{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face on Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Mediapipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True)\n",
    "# Function to detect landmarks\n",
    "def detect_landmarks(image):\n",
    "    results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    if results.multi_face_landmarks:\n",
    "        return results.multi_face_landmarks[0]\n",
    "    return None\n",
    "\n",
    "# Function to get landmarks list\n",
    "def get_landmarks_list(landmarks, image_shape):\n",
    "    h, w = image_shape[:2]\n",
    "    return [(int(landmark.x * w), int(landmark.y * h)) for landmark in landmarks.landmark]\n",
    "\n",
    "# Load images\n",
    "image1 = cv2.imread(r'C:\\Users\\myfir\\My Drive\\Skyline\\Personal Expression\\Smile.jpg')\n",
    "image2 = cv2.imread(r'C:\\Users\\myfir\\My Drive\\Skyline\\Personal Expression\\Neutral.jpg')\n",
    "\n",
    "# Detect landmarks\n",
    "landmarks1 = detect_landmarks(image1)\n",
    "landmarks2 = detect_landmarks(image2)\n",
    "\n",
    "if not landmarks1 or not landmarks2:\n",
    "    raise ValueError(\"Face landmarks not detected in one or both images\")\n",
    "\n",
    "# Get landmarks lists\n",
    "\n",
    "landmarks_list1 = get_landmarks_list(landmarks1, image1.shape)\n",
    "landmarks_list2 = get_landmarks_list(landmarks2, image2.shape)\n",
    "\n",
    "# Create a transformation matrix to align the landmarks\n",
    "pts1 = np.float32(landmarks_list1)\n",
    "pts2 = np.float32(landmarks_list2)\n",
    "transformation_matrix, _ = cv2.estimateAffinePartial2D(pts1, pts2)\n",
    "\n",
    "# Transform landmarks from the first face\n",
    "transformed_landmarks = cv2.transform(np.array(landmarks_list1).reshape(-1, 1, 2), transformation_matrix).reshape(-1, 2)\n",
    "\n",
    "# Draw original landmarks on the second face in blue\n",
    "for (x, y) in landmarks_list2:\n",
    "    cv2.circle(image2, (int(x), int(y)), 1, (255, 0, 0), -1)\n",
    "\n",
    "# Draw transformed landmarks from the first face on the second face in red\n",
    "for (x, y) in transformed_landmarks:\n",
    "    cv2.circle(image2, (int(x), int(y)), 1, (0, 0, 255), -1)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('NEUTRAL | Blue is Smile, Red is Neutral', image2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "\n",
    "# Initialize Mediapipe Face Mesh\n",
    "mp_face_mesh = mp.solutions.face_mesh\n",
    "face_mesh = mp_face_mesh.FaceMesh(static_image_mode=True)\n",
    "\n",
    "# Function to detect landmarks\n",
    "def detect_landmarks(image):\n",
    "    results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "    if results.multi_face_landmarks:\n",
    "        return results.multi_face_landmarks[0]\n",
    "    return None\n",
    "\n",
    "# Function to get landmarks list\n",
    "def get_landmarks_list(landmarks, image_shape):\n",
    "    h, w = image_shape[:2]\n",
    "    return [(int(landmark.x * w), int(landmark.y * h)) for landmark in landmarks.landmark]\n",
    "\n",
    "# Load images\n",
    "image1 = cv2.imread(r'C:\\Users\\myfir\\My Drive\\Skyline\\Personal Expression\\Close Up Smile.jpg')\n",
    "image2 = cv2.imread(r'C:\\Users\\myfir\\My Drive\\Skyline\\Personal Expression\\Close up Neutral.jpg')\n",
    "\n",
    "# Detect landmarks\n",
    "landmarks1 = detect_landmarks(image1)\n",
    "landmarks2 = detect_landmarks(image2)\n",
    "\n",
    "if not landmarks1 or not landmarks2:\n",
    "    raise ValueError(\"Face landmarks not detected in one or both images\")\n",
    "\n",
    "# Get landmarks lists\n",
    "\n",
    "landmarks_list1 = get_landmarks_list(landmarks1, image1.shape)\n",
    "landmarks_list2 = get_landmarks_list(landmarks2, image2.shape)\n",
    "\n",
    "# Create a transformation matrix to align the landmarks\n",
    "pts1 = np.float32(landmarks_list1)\n",
    "pts2 = np.float32(landmarks_list2)\n",
    "transformation_matrix, _ = cv2.estimateAffinePartial2D(pts1, pts2)\n",
    "\n",
    "# Transform landmarks from the first face\n",
    "transformed_landmarks = cv2.transform(np.array(landmarks_list1).reshape(-1, 1, 2), transformation_matrix).reshape(-1, 2)\n",
    "\n",
    "# Draw original landmarks on the second face in blue\n",
    "for (x, y) in landmarks_list2:\n",
    "    cv2.circle(image2, (int(x), int(y)), 1, (255, 0, 0), -1)\n",
    "\n",
    "# Draw transformed landmarks from the first face on the second face in red\n",
    "for (x, y) in transformed_landmarks:\n",
    "    cv2.circle(image2, (int(x), int(y)), 1, (0, 0, 255), -1)\n",
    "\n",
    "# Display the result\n",
    "cv2.imshow('NEUTRAL | Blue is Smile, Red is Neutral', image2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Face on Cartoon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\myfir\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\google\\protobuf\\symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Import the necessary modules.\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "import numpy as np\n",
    "\n",
    "# STEP 2: Create an FaceLandmarker object.\n",
    "base_options = python.BaseOptions(model_asset_path='face_landmarker.task')\n",
    "options = vision.FaceLandmarkerOptions(base_options=base_options,\n",
    "                                       output_face_blendshapes=True,\n",
    "                                       output_facial_transformation_matrixes=True,\n",
    "                                       num_faces=1)\n",
    "detector = vision.FaceLandmarker.create_from_options(options)\n",
    "\n",
    "# STEP 3: Load the input image.\n",
    "control = mp.Image.create_from_file(r'C:\\Users\\myfir\\My Drive\\Skyline\\Personal Expression\\Neutral.jpg')\n",
    "test = mp.Image.create_from_file(r'C:\\Users\\myfir\\My Drive\\Skyline\\Personal Expression\\Smile.jpg')\n",
    "\n",
    "# STEP 4: Detect face landmarks from the input image.\n",
    "control_result = detector.detect(control)\n",
    "test_result = detector.detect(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(neutral_result\u001b[38;5;241m.\u001b[39mface_landmarks) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(emotion_result\u001b[38;5;241m.\u001b[39mface_landmarks) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "assert len(control_result.face_landmarks) == 1 , 'Not exactly one face detected in control image'\n",
    "assert len(test_result.face_landmarks) == 1, 'Not exactly one face detected in test image'\n",
    "\n",
    "xControl = [landmark.x for landmark in control_result.face_landmarks[0]]\n",
    "yControl = [landmark.y for landmark in control_result.face_landmarks[0]]\n",
    "\n",
    "xTest = [landmark.x for landmark in test_result.face_landmarks[0]]\n",
    "yTest = [landmark.y for landmark in test_result.face_landmarks[0]]\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
